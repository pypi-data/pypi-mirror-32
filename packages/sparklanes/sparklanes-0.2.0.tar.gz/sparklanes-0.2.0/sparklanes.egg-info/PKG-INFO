Metadata-Version: 2.1
Name: sparklanes
Version: 0.2.0
Summary: A lightweight framework to build and execute data processing pipelines in pyspark (Apache Spark's python API)
Home-page: https://github.com/ksbg/sparklanes
Author: Kevin Baumgarten
Author-email: kevin@ksbg.io
License: UNKNOWN
Download-URL: https://github.com/ksbg/sparklanes/archive/0.2.zip
Description: sparklanes
        ==========
        
        [![PyPI version](https://badge.fury.io/py/sparklanes.svg)](https://badge.fury.io/py/sparklanes)
        ![Python versions](https://img.shields.io/pypi/pyversions/Django.svg)
        [![Build Status](https://travis-ci.org/ksbg/sparklanes.svg?branch=master)](https://travis-ci.org/ksbg/sparklanes?branch=master)
        [![Coverage Status](https://coveralls.io/repos/github/ksbg/sparklanes/badge.svg?branch=master)](https://coveralls.io/github/ksbg/sparklanes?branch=master)
        [![Doc status](https://sparklanes.readthedocs.io/en/latest/?badge=latest)](https://sparklanes.readthedocs.io)
        ![pylint Score](https://mperlet.github.io/pybadge/badges/9.88.svg)
        ![license](https://img.shields.io/github/license/ksbg/sparklanes.svg)
        
        
        sparklanes is a lightweight data processing framework for Apache Spark
        written in Python. It was built with the intention to make building
        complex spark processing pipelines simpler, by shifting the focus
        towards writing data processing code without having to spent much time
        on the surrounding application architecture.
        
        Data processing pipelines, or *lanes*, are built by stringing together
        encapsulated processor classes, which allows creation of lane definitions
        with an arbitrary processor order, where processors can be easily
        removed, added or swapped.
        
        Processing pipelines can be defined using *lane configuration YAML files*,
        to then be packaged and submitted to spark using a single command.
        Alternatively, the same can be achieved manually by using the framework's
        API.
        
        Documentation
        -------------
        
        Find the documentation on [sparklanes.readthedocs.io](https://sparklanes.readthedocs.io).
        
        Also check out the [example Jupyter notebook](example/iris_example.ipynb).
        
Keywords: spark,pyspark,data,processing,preprocessing,pipelines
Platform: UNKNOWN
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, <4
Description-Content-Type: text/markdown
