# Serve after softmax train

We can use `guild serve --print-model-info` to print information about
a saved model generated by a run. By default the latest run is used.

    >>> run("guild serve --print-model-info")
    - signature_defs:
        serving_default:
          inputs:
            inputs:
              dtype: DT_FLOAT
              shape: [-1, 784]
              tensor: Placeholder:0
          method_name: tensorflow/serving/predict
          outputs:
            classes:
              dtype: DT_INT64
              shape: [-1]
              tensor: ArgMax_2:0
            probabilities:
              dtype: DT_FLOAT
              shape: [-1, 10]
              tensor: Softmax:0
      tags: [serve]
      tensorflow_git_version: v1.8.0...
      tensorflow_version: 1.8.0
    <exit 0>

`guild serve` will load the saved model generated by the softmax
training and use it to make predictions. The default behavior, shown
below, is to serve the latest run.

    >>> run("echo Testing serve && "
    ...     "guild serve --test serving_default --test-json-instances %s"
    ...     % sample("serve/mnist-instances.json"))
    Testing serve
    ...
    {
      "predictions": [
        {
          "classes": 3,
          "probabilities": [
            ...
          ]
        },
        {
          "classes": 4,
          "probabilities": [
            ...
          ]
        }
      ]
    }
    <exit 0>
