Metadata-Version: 2.1
Name: tensorpack
Version: 0.8.6
Summary: Neural Network Toolbox on TensorFlow
Home-page: https://github.com/tensorpack/tensorpack
Author: TensorPack contributors
Author-email: ppwwyyxxc@gmail.com
License: Apache
Keywords: tensorflow,deep learning,neural network
Platform: UNKNOWN
Description-Content-Type: text/x-rst
Provides-Extra: all
Requires-Dist: numpy
Requires-Dist: six
Requires-Dist: termcolor (>=1.1)
Requires-Dist: tabulate (>=0.7.7)
Requires-Dist: tqdm (>4.11.1)
Requires-Dist: pyarrow (>=0.9.0)
Requires-Dist: pyzmq (>=16)
Requires-Dist: subprocess32; python_version < "3.0"
Requires-Dist: functools32; python_version < "3.0"
Provides-Extra: all
Requires-Dist: pillow; extra == 'all'
Requires-Dist: scipy; extra == 'all'
Requires-Dist: h5py; extra == 'all'
Requires-Dist: lmdb (>=0.92); extra == 'all'
Requires-Dist: matplotlib; extra == 'all'
Requires-Dist: scikit-learn; extra == 'all'
Provides-Extra: all
Requires-Dist: tornado; ( python_version < "3.0") and extra == 'all'

.. figure:: .github/tensorpack.png
   :alt: Tensorpack

   Tensorpack
Tensorpack is a training interface based on TensorFlow.

|Build Status| |ReadTheDoc| |Gitter chat| |model-zoo|

Features:
---------

It's Yet Another TF high-level API, with **speed**, **readability** and
**flexibility** built together.

1. Focus on **training speed**.

   -  Speed comes for free with tensorpack -- it uses TensorFlow in the
      **efficient way** with no extra overhead. On different CNNs, it
      runs training `1.2~5x
      faster <https://github.com/tensorpack/benchmarks/tree/master/other-wrappers>`__
      than the equivalent Keras code.

   -  Data-parallel multi-GPU/distributed training strategy is
      off-the-shelf to use. It scales as well as Google's `official
      benchmark <https://www.tensorflow.org/performance/benchmarks>`__.

   -  See
      `tensorpack/benchmarks <https://github.com/tensorpack/benchmarks>`__
      for some benchmark scripts.

2. Focus on **large datasets**.

   -  `You don't usually need
      ``tf.data`` <http://tensorpack.readthedocs.io/tutorial/input-source.html#tensorflow-reader-cons>`__.
      Symbolic programming often makes data processing harder.
      Tensorpack helps you efficiently process large datasets (e.g.
      ImageNet) in **pure Python** with autoparallelization.

3. It's not a model wrapper.

   -  There are too many symbolic function wrappers in the world.
      Tensorpack includes only a few common models. But you can use any
      symbolic function library inside tensorpack, including
      tf.layers/Keras/slim/tflearn/tensorlayer/....

See
`tutorials <http://tensorpack.readthedocs.io/tutorial/index.html#user-tutorials>`__
to know more about these features.

`Examples <examples>`__:
------------------------

We refuse toy examples. Instead of showing you 10 arbitrary networks
trained on toy datasets, `tensorpack examples <examples>`__ faithfully
replicate papers and care about reproducing numbers, demonstrating its
flexibility for actual research.

Vision:
~~~~~~~

-  `Train ResNet <examples/ResNet>`__ and `other
   models <examples/ImageNetModels>`__ on ImageNet.
-  `Train Faster-RCNN / Mask-RCNN on COCO object
   detection <examples/FasterRCNN>`__
-  `Generative Adversarial Network(GAN) variants <examples/GAN>`__,
   including DCGAN, InfoGAN, Conditional GAN, WGAN, BEGAN, DiscoGAN,
   Image to Image, CycleGAN.
-  `DoReFa-Net: train binary / low-bitwidth CNN on
   ImageNet <examples/DoReFa-Net>`__
-  `Fully-convolutional Network for Holistically-Nested Edge
   Detection(HED) <examples/HED>`__
-  `Spatial Transformer Networks on MNIST
   addition <examples/SpatialTransformer>`__
-  `Visualize CNN saliency maps <examples/Saliency>`__
-  `Similarity learning on MNIST <examples/SimilarityLearning>`__

Reinforcement Learning:
~~~~~~~~~~~~~~~~~~~~~~~

-  `Deep Q-Network(DQN) variants on Atari
   games <examples/DeepQNetwork>`__, including DQN, DoubleDQN,
   DuelingDQN.
-  `Asynchronous Advantage Actor-Critic(A3C) with demos on OpenAI
   Gym <examples/A3C-Gym>`__

Speech / NLP:
~~~~~~~~~~~~~

-  `LSTM-CTC for speech recognition <examples/CTC-TIMIT>`__
-  `char-rnn for fun <examples/Char-RNN>`__
-  `LSTM language model on PennTreebank <examples/PennTreebank>`__

Install:
--------

Dependencies:

-  Python 2.7 or 3
-  Python bindings for OpenCV (Optional, but required by a lot of
   features)
-  TensorFlow >= 1.3.0 (Optional if you only want to use
   ``tensorpack.dataflow`` alone as a data processing library)

   ::

       # install git, then:
       pip install -U git+https://github.com/tensorpack/tensorpack.git
       # or add `--user` to avoid system-wide installation.

Citing Tensorpack:
------------------

If you use Tensorpack in your research or wish to refer to the examples,
please cite with:

::

    @misc{wu2016tensorpack,
      title={Tensorpack},
      author={Wu, Yuxin and others},
      howpublished={\url{https://github.com/tensorpack/}},
      year={2016}
    }

.. |Build Status| image:: https://travis-ci.org/tensorpack/tensorpack.svg?branch=master
   :target: https://travis-ci.org/tensorpack/tensorpack
.. |ReadTheDoc| image:: https://readthedocs.org/projects/tensorpack/badge/?version=latest
   :target: http://tensorpack.readthedocs.io/en/latest/index.html
.. |Gitter chat| image:: https://badges.gitter.im/gitterHQ/gitter.png
   :target: https://gitter.im/tensorpack/users
.. |model-zoo| image:: https://img.shields.io/badge/model-zoo-brightgreen.svg
   :target: http://models.tensorpack.com


